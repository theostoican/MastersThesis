{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theostoican/MastersThesis/blob/main/training_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "4cKo7_tWleLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c30cee4-1a2c-468d-abe3-9d6bbf3ee087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dict_minimize in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from dict_minimize) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from dict_minimize) (1.4.1)\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import csv\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "!pip install dict_minimize\n",
        "from dict_minimize.torch_api import minimize\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8SjHkIMoI_B"
      },
      "source": [
        "# Various modelling parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "F8ktizbMoKWO"
      },
      "outputs": [],
      "source": [
        "#N is batch size; D_in is input dimension;\n",
        "#H is the dimension of the hidden layer; D_out is output dimension.\n",
        "N, D_in, H_teacher, H_student, D_out = 1, 2, 4, 5, 1\n",
        "num_experiments = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ptEq_k5KeK6"
      },
      "source": [
        "# Dataset creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7WSK5OS-_Jb",
        "outputId": "9bdf6dda-859e-4ec9-9bb7-2c323e8121b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1681\n"
          ]
        }
      ],
      "source": [
        "def construct_dataset():\n",
        "  data = []\n",
        "  for y in np.arange(-5, 5.1, .25):\n",
        "    for x in np.arange(-5, 5.1, .25):\n",
        "      data.append([x, y])\n",
        "  return data\n",
        "\n",
        "data = torch.Tensor(construct_dataset()) \n",
        "print(len(construct_dataset()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0ZEwEx3Kg9_"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "QLlxqBcnzo2e"
      },
      "outputs": [],
      "source": [
        "class TeacherNetwork(nn.Module):\n",
        "  def __init__(self, D_in, H, D_out):\n",
        "    \"\"\"\n",
        "    In the constructor we instantiate two nn.Linear modules and assign them as\n",
        "    member variables.\n",
        "\n",
        "    D_in: input dimension\n",
        "    H: dimension of hidden layer\n",
        "    D_out: output dimension of the first layer\n",
        "    \"\"\"\n",
        "    super(TeacherNetwork, self).__init__()\n",
        "    self.linear1 = nn.Linear(D_in, H, bias=False) \n",
        "    self.linear2 = nn.Linear(H, D_out, bias=False)\n",
        "    self.linear1.weight = torch.nn.Parameter(torch.transpose(torch.Tensor([[0.6, -0.5, -0.2, 0.1], [0.5, 0.5, -0.6, -0.6]]), 0, 1))\n",
        "    self.linear2.weight = torch.nn.Parameter(torch.transpose(torch.Tensor([[1], [-1], [1], [-1]]), 0, 1))\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    In the forward function we accept a Variable of input data and we must\n",
        "    return a Variable of output data. We can use Modules defined in the\n",
        "    constructor as well as arbitrary operators on Variables.\n",
        "    \"\"\"\n",
        "    h_sigmoid = torch.sigmoid(self.linear1(x))\n",
        "    y_pred = self.linear2(h_sigmoid)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "COkLdjEOmBJV"
      },
      "outputs": [],
      "source": [
        "class StudentNetwork(nn.Module):\n",
        "  def __init__(self, D_in, H, D_out):\n",
        "    \"\"\"\n",
        "    In the constructor we instantiate two nn.Linear modules and assign them as\n",
        "    member variables.\n",
        "\n",
        "    D_in: input dimension\n",
        "    H: dimension of hidden layer\n",
        "    D_out: output dimension of the first layer\n",
        "    \"\"\"\n",
        "    super(StudentNetwork, self).__init__()\n",
        "    self.linear1 = nn.Linear(D_in, H, bias=False) \n",
        "    self.linear2 = nn.Linear(H, D_out, bias=False)\n",
        "    nn.init.xavier_uniform_(self.linear1.weight)\n",
        "    nn.init.xavier_uniform_(self.linear2.weight)\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    In the forward function we accept a Variable of input data and we must\n",
        "    return a Variable of output data. We can use Modules defined in the\n",
        "    constructor as well as arbitrary operators on Variables.\n",
        "    \"\"\"\n",
        "    h_sigmoid = torch.sigmoid(self.linear1(x))\n",
        "    y_pred = self.linear2(h_sigmoid)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh4A8WS3HzeU"
      },
      "source": [
        "# Generation of the labels based on the teacher model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "ILSXsIRu3U18"
      },
      "outputs": [],
      "source": [
        "teacher_model = TeacherNetwork(D_in, H_teacher, D_out)\n",
        "y_labels = teacher_model(data).detach()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZrYxLLwKk6Q"
      },
      "source": [
        "# Training helper method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "kS2Ri_ya9Npv"
      },
      "outputs": [],
      "source": [
        "def train(model, x, y_labels, N = 1000, Ninner = 10**3, Nstart = 10,\n",
        "          maxtime = 10 ** 3, nlopt_threshold = 1e-7,\n",
        "          collect_history = True):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "  loss_fn = nn.MSELoss()\n",
        "  loss_vals = []\n",
        "  trace = []\n",
        "  if collect_history:\n",
        "    trace.append((copy.deepcopy(model.linear1.weight.data.detach().numpy()),\n",
        "                  copy.deepcopy(model.linear2.weight.data.detach().numpy())))\n",
        "  for i in range(N):\n",
        "    loss_tmp = []\n",
        "    for j in range(Ninner):\n",
        "      y = model(x)\n",
        "      loss = loss_fn(y, y_labels)\n",
        "      loss_grad = torch.autograd.grad(loss, model.parameters(), retain_graph=True)\n",
        "      loss_tmp.append(loss.item())\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward(retain_graph=True)\n",
        "      optimizer.step()\n",
        "      if i == 0 and (j % Nstart == 0) and j > 0:\n",
        "        loss_vals.append(np.mean(loss_tmp[j - Nstart : j]))\n",
        "        if collect_history:\n",
        "          trace.append((copy.deepcopy(model.linear1.weight.data.detach().numpy()),\n",
        "                        copy.deepcopy(model.linear2.weight.data.detach().numpy())))\n",
        "    loss_vals.append(np.mean(loss_tmp))\n",
        "    if collect_history:\n",
        "      trace.append((copy.deepcopy(model.linear1.weight.data.detach().numpy()),\n",
        "                    copy.deepcopy(model.linear2.weight.data.detach().numpy())))\n",
        "    # stopping criterion\n",
        "    cnt = 0\n",
        "    for g in loss_grad:\n",
        "        g_vector = g.contiguous().view(-1) if cnt == 0 else torch.cat([g_vector, g.contiguous().view(-1)])\n",
        "        cnt = 1\n",
        "    print(\"Iteration: %d, loss: %s, gradient norm: %s\" % (Ninner * i, np.mean(loss_tmp), torch.norm(g_vector)))\n",
        "    if torch.norm(g_vector) <= 2e-6:\n",
        "      break\n",
        "  return loss_vals, trace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlZpml_4MOQD"
      },
      "source": [
        "# Hessian evaluation helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "mXEHxyklMQgi"
      },
      "outputs": [],
      "source": [
        "def eval_hessian(loss_grad, model):\n",
        "  cnt = 0\n",
        "  for g in loss_grad:\n",
        "      g_vector = g.contiguous().view(-1) if cnt == 0 else torch.cat([g_vector, g.contiguous().view(-1)])\n",
        "      cnt = 1\n",
        "  grad_norm = torch.norm(g_vector)\n",
        "  l = g_vector.size(0)\n",
        "  hessian = torch.zeros(l, l)\n",
        "  for idx in range(l):\n",
        "      grad2rd = torch.autograd.grad(g_vector[idx], model.parameters(), create_graph=True)\n",
        "      cnt = 0\n",
        "      for g in grad2rd: \n",
        "          g2 = g.contiguous().view(-1) if cnt == 0 else torch.cat([g2, g.contiguous().view(-1)])\n",
        "          cnt = 1\n",
        "      hessian[idx] = g2\n",
        "  # Symmetrize the Hessian.\n",
        "  hessian = (hessian + hessian.T) / 2\n",
        "  return grad_norm.cpu().data.numpy(), hessian.cpu().data.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV8HjfUxcupO"
      },
      "source": [
        "# Actual training and hessian computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-4dScUFCP-2",
        "outputId": "b285221f-f2eb-4bea-a4f0-c410a2375f04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0, loss: 0.197742076843977, gradient norm: tensor(0.4996)\n",
            "Iteration: 1000, loss: 0.07966146493330598, gradient norm: tensor(0.1781)\n",
            "Iteration: 2000, loss: 0.04707760410383344, gradient norm: tensor(0.1130)\n",
            "Iteration: 3000, loss: 0.025782784240320326, gradient norm: tensor(0.0891)\n",
            "Iteration: 4000, loss: 0.011106316794175654, gradient norm: tensor(0.0481)\n",
            "Iteration: 5000, loss: 0.005551547456067055, gradient norm: tensor(0.0238)\n",
            "Iteration: 6000, loss: 0.0033425123922061176, gradient norm: tensor(0.0152)\n",
            "Iteration: 7000, loss: 0.001939776205108501, gradient norm: tensor(0.0094)\n",
            "Iteration: 8000, loss: 0.0011133711663424038, gradient norm: tensor(0.0055)\n",
            "Iteration: 9000, loss: 0.0006310332672437653, gradient norm: tensor(0.0034)\n",
            "Iteration: 10000, loss: 0.0003393747188092675, gradient norm: tensor(0.0019)\n",
            "Iteration: 11000, loss: 0.00019524677406297997, gradient norm: tensor(0.0009)\n",
            "Iteration: 12000, loss: 0.00014309749263338744, gradient norm: tensor(0.0004)\n",
            "Iteration: 13000, loss: 0.00012549573585420148, gradient norm: tensor(0.0002)\n",
            "Iteration: 14000, loss: 0.00011711790655681398, gradient norm: tensor(0.0002)\n",
            "Iteration: 15000, loss: 0.00011058462012442761, gradient norm: tensor(0.0001)\n",
            "Iteration: 16000, loss: 0.00010418745695642429, gradient norm: tensor(8.6146e-05)\n",
            "Iteration: 17000, loss: 9.814141394599573e-05, gradient norm: tensor(5.6957e-05)\n",
            "Iteration: 18000, loss: 9.345336713886354e-05, gradient norm: tensor(2.9142e-05)\n",
            "Iteration: 19000, loss: 9.099382245767629e-05, gradient norm: tensor(2.1006e-05)\n",
            "Iteration: 20000, loss: 8.925183723476949e-05, gradient norm: tensor(1.6121e-05)\n",
            "Iteration: 21000, loss: 8.746780714864144e-05, gradient norm: tensor(9.0413e-06)\n",
            "Iteration: 22000, loss: 8.635502843389986e-05, gradient norm: tensor(1.4483e-05)\n",
            "Iteration: 23000, loss: 8.592440566280857e-05, gradient norm: tensor(2.9496e-06)\n",
            "Iteration: 24000, loss: 8.574005238915561e-05, gradient norm: tensor(3.1147e-06)\n",
            "Iteration: 25000, loss: 8.542522136121988e-05, gradient norm: tensor(5.7325e-06)\n",
            "Iteration: 26000, loss: 8.43394636613084e-05, gradient norm: tensor(1.4973e-05)\n",
            "Iteration: 27000, loss: 8.229164619115182e-05, gradient norm: tensor(1.2598e-05)\n",
            "Iteration: 28000, loss: 8.041977147513535e-05, gradient norm: tensor(7.0921e-05)\n",
            "Iteration: 29000, loss: 7.951672161289025e-05, gradient norm: tensor(2.4556e-05)\n",
            "Iteration: 30000, loss: 7.912315047724405e-05, gradient norm: tensor(3.4971e-06)\n",
            "Iteration: 31000, loss: 7.889978488674387e-05, gradient norm: tensor(2.4816e-05)\n",
            "Iteration: 32000, loss: 7.869313476112438e-05, gradient norm: tensor(4.5513e-06)\n",
            "Iteration: 33000, loss: 7.824751552107045e-05, gradient norm: tensor(7.8814e-06)\n",
            "Iteration: 34000, loss: 7.708518424624345e-05, gradient norm: tensor(1.6663e-05)\n",
            "Iteration: 35000, loss: 7.571763813029975e-05, gradient norm: tensor(2.2949e-05)\n",
            "Iteration: 36000, loss: 7.47101861416013e-05, gradient norm: tensor(1.2778e-05)\n",
            "Iteration: 37000, loss: 7.409250605996931e-05, gradient norm: tensor(1.1814e-05)\n",
            "Iteration: 38000, loss: 7.37712539776112e-05, gradient norm: tensor(2.3907e-05)\n",
            "Iteration: 39000, loss: 7.363454301957972e-05, gradient norm: tensor(2.7333e-05)\n",
            "Iteration: 40000, loss: 7.358695084258216e-05, gradient norm: tensor(1.3201e-05)\n",
            "Iteration: 41000, loss: 7.356882938620401e-05, gradient norm: tensor(2.3870e-05)\n",
            "Iteration: 42000, loss: 7.355676982842851e-05, gradient norm: tensor(1.4764e-05)\n",
            "Iteration: 43000, loss: 7.354581580148079e-05, gradient norm: tensor(2.0976e-05)\n",
            "Iteration: 44000, loss: 7.353535811853363e-05, gradient norm: tensor(1.9148e-06)\n",
            "smallest eigenvalue:  -1.9506363e-06\n"
          ]
        }
      ],
      "source": [
        "student_model = StudentNetwork(D_in, H_student, D_out)\n",
        "loss_vals, trace = train(student_model, data, y_labels)\n",
        "last_loss_val = loss_vals[-1]\n",
        "\n",
        "loss_grad = torch.autograd.grad(nn.MSELoss()(student_model(data), y_labels), student_model.parameters(), create_graph=True)\n",
        "grad_norm, hessian = eval_hessian(loss_grad, student_model)\n",
        "smallest_eigenvalue = np.min(np.linalg.eigvals(hessian))\n",
        "\n",
        "print('smallest eigenvalue: ', smallest_eigenvalue)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F7kBJPoLS_h"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "JYMYC8b5VqT1"
      },
      "outputs": [],
      "source": [
        "teacher_neurons_x = [0.6, -0.5, -0.2, 0.1]\n",
        "teacher_neurons_y = [0.5, 0.5, -0.6, -0.6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mflgj_AbLToB",
        "outputId": "9f8f7640-ffad-4132-b314-1bf0c97bee8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f9f91974cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "neuron_0_w_x = []\n",
        "neuron_0_w_y = []\n",
        "neuron_0_a = []\n",
        "\n",
        "neuron_1_w_x = []\n",
        "neuron_1_w_y = []\n",
        "neuron_1_a = []\n",
        "\n",
        "neuron_2_w_x = []\n",
        "neuron_2_w_y = []\n",
        "neuron_2_a = []\n",
        "\n",
        "neuron_3_w_x = []\n",
        "neuron_3_w_y = []\n",
        "neuron_3_a = []\n",
        "\n",
        "neuron_4_w_x = []\n",
        "neuron_4_w_y = []\n",
        "neuron_4_a = []\n",
        "\n",
        "for (inp_weights, out_weights) in trace:\n",
        "  neuron_0_w_x.append(inp_weights[0][0])\n",
        "  neuron_0_w_y.append(inp_weights[0][1])\n",
        "  neuron_0_a.append(out_weights[0][0])\n",
        "\n",
        "  neuron_1_w_x.append(inp_weights[1][0])\n",
        "  neuron_1_w_y.append(inp_weights[1][1])\n",
        "  neuron_1_a.append(out_weights[0][1])\n",
        "\n",
        "  neuron_2_w_x.append(inp_weights[2][0])\n",
        "  neuron_2_w_y.append(inp_weights[2][1])\n",
        "  neuron_2_a.append(out_weights[0][2])\n",
        "\n",
        "  neuron_3_w_x.append(inp_weights[3][0])\n",
        "  neuron_3_w_y.append(inp_weights[3][1])\n",
        "  neuron_3_a.append(out_weights[0][3])\n",
        "\n",
        "  neuron_4_w_x.append(inp_weights[4][0])\n",
        "  neuron_4_w_y.append(inp_weights[4][1])\n",
        "  neuron_4_a.append(out_weights[0][4])\n",
        "\n",
        "plt.plot(neuron_0_w_x, neuron_0_w_y)\n",
        "plt.plot(neuron_1_w_x, neuron_1_w_y)\n",
        "plt.plot(neuron_2_w_x, neuron_2_w_y)\n",
        "plt.plot(neuron_3_w_x, neuron_3_w_y)\n",
        "plt.plot(neuron_4_w_x, neuron_4_w_y)\n",
        "\n",
        "plt.scatter(teacher_neurons_x, teacher_neurons_y, marker=\"*\")\n",
        "\n",
        "outgoing_weights = [neuron_0_a[-1], neuron_1_a[-1], neuron_2_a[-1], neuron_3_a[-1], neuron_4_a[-1]]\n",
        "plt.scatter([neuron_0_w_x[-1], neuron_1_w_x[-1], neuron_2_w_x[-1], neuron_3_w_x[-1], neuron_4_w_x[-1]],\n",
        "            [neuron_0_w_y[-1], neuron_1_w_y[-1], neuron_2_w_y[-1], neuron_3_w_y[-1], neuron_4_w_y[-1]],\n",
        "            c = outgoing_weights,\n",
        "            cmap=matplotlib.cm.jet)\n",
        "plt.colorbar()\n",
        "\n",
        "# Teacher's neurons\n",
        "#[0.6, -0.5, -0.2, 0.1],\n",
        "#[0.5, 0.5, -0.6, -0.6],"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second order optimization"
      ],
      "metadata": {
        "id": "JjTe7aE14Dac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DummyNetwork(nn.Module):\n",
        "  def __init__(self, D_in, H, D_out, w_in, w_out):\n",
        "    \"\"\"\n",
        "    In the constructor we instantiate two nn.Linear modules and assign them as\n",
        "    member variables.\n",
        "\n",
        "    D_in: input dimension\n",
        "    H: dimension of hidden layer\n",
        "    D_out: output dimension of the first layer\n",
        "    \"\"\"\n",
        "    super(DummyNetwork, self).__init__()\n",
        "    self.linear1 = nn.Linear(D_in, H, bias=False) \n",
        "    self.linear2 = nn.Linear(H, D_out, bias=False)\n",
        "    self.linear1.weight = torch.nn.Parameter(w_in)\n",
        "    self.linear2.weight = torch.nn.Parameter(w_out)\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    In the forward function we accept a Variable of input data and we must\n",
        "    return a Variable of output data. We can use Modules defined in the\n",
        "    constructor as well as arbitrary operators on Variables.\n",
        "    \"\"\"\n",
        "    h_sigmoid = torch.sigmoid(self.linear1(x))\n",
        "    y_pred = self.linear2(h_sigmoid)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "WDicCa3cV1xM"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def d_loss(params):\n",
        "  w_in, w_out = params[\"w_in\"], params[\"w_out\"]\n",
        "  dummy_model = DummyNetwork(D_in, H_student, D_out, w_in, w_out)\n",
        "  obj = nn.MSELoss()(dummy_model(data), y_labels)\n",
        "  dw_in, dw_out = torch.autograd.grad(obj, dummy_model.parameters())\n",
        "  d_obj = OrderedDict([(\"w_in\", dw_in), (\"w_out\", dw_out)])\n",
        "  return obj, d_obj"
      ],
      "metadata": {
        "id": "TuACp-6HWtBD"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = OrderedDict([(\"w_in\", torch.Tensor(trace[-1][0])), (\"w_out\", torch.Tensor(trace[-1][1]))])\n",
        "lb_dict = OrderedDict([(\"w_in\", torch.Tensor(trace[-1][0] - 1)), (\"w_out\", torch.Tensor(trace[-1][1] - 1))])\n",
        "ub_dict = OrderedDict([(\"w_in\", torch.Tensor(trace[-1][0] + 1)), (\"w_out\", torch.Tensor(trace[-1][1] + 1))])\n",
        "print('old params: ',params)\n",
        "# params = minimize(d_loss, params, method=\"\", lb_dict = lb_dict, ub_dict = ub_dict,\n",
        "#                   options={\"disp\": True , \"maxiter\": 10 ** 3}, tol=1e-8)\n",
        "params = minimize(d_loss, params, method=\"SLSQP\", lb_dict = lb_dict, ub_dict = ub_dict,\n",
        "                  options={\"disp\": True , \"maxiter\": 10 ** 4}, tol=1e-40)\n",
        "print('new params: ',params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm6OGZBNYuV7",
        "outputId": "7d434a2a-0741-4b71-b148-ae8c2ca45d00"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "old params:  OrderedDict([('w_in', tensor([[ 1.5433, -1.1807],\n",
            "        [-0.4119,  0.1066],\n",
            "        [ 0.8458,  1.0005],\n",
            "        [ 1.9352, -1.4094],\n",
            "        [ 0.8392,  0.8046]])), ('w_out', tensor([[ 0.6462, -0.6348, -0.5418, -0.4183,  0.9488]]))])\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: 7.35301582608372e-05\n",
            "            Iterations: 2\n",
            "            Function evaluations: 15\n",
            "            Gradient evaluations: 2\n",
            "new params:  OrderedDict([('w_in', tensor([[ 1.5433, -1.1807],\n",
            "        [-0.4119,  0.1066],\n",
            "        [ 0.8458,  1.0005],\n",
            "        [ 1.9352, -1.4094],\n",
            "        [ 0.8392,  0.8046]], requires_grad=True)), ('w_out', tensor([[ 0.6462, -0.6348, -0.5418, -0.4183,  0.9488]], requires_grad=True))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New smallest eigenvalue"
      ],
      "metadata": {
        "id": "9flDuKrBgJ68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_model = DummyNetwork(D_in, H_student, D_out, params[\"w_in\"], params[\"w_out\"])\n",
        "print(nn.MSELoss()(dummy_model(data), y_labels))\n",
        "loss_grad = torch.autograd.grad(nn.MSELoss()(dummy_model(data), y_labels), dummy_model.parameters(), create_graph=True)\n",
        "grad_norm, hessian = eval_hessian(loss_grad, dummy_model)\n",
        "print(hessian)\n",
        "smallest_eigenvalue = np.min(np.linalg.eigvals(hessian))\n",
        "print('new smallest eigenvelue:', smallest_eigenvalue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwNZPkIvek9Y",
        "outputId": "1d2922fc-a7ef-465b-b7b6-5645bd4903c6"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7.3530e-05, grad_fn=<MseLossBackward0>)\n",
            "[[ 4.88998219e-02  5.82427867e-02 -5.73380068e-02 -6.36745468e-02\n",
            "  -3.16338986e-03 -1.26569753e-03 -2.60320939e-02 -3.22904661e-02\n",
            "   6.89016422e-03  3.75220878e-03  2.11953651e-02 -3.16399708e-02\n",
            "   7.52925947e-02  2.90156864e-02  7.46478736e-02]\n",
            " [ 5.82427867e-02  7.66534060e-02 -6.36745468e-02 -9.06984136e-02\n",
            "  -1.26569741e-03 -4.06327797e-03 -3.22904661e-02 -4.35579196e-02\n",
            "   3.75220901e-03  1.02691706e-02 -3.81092401e-03 -3.06939967e-02\n",
            "   9.42766815e-02  3.47003620e-03  9.24869329e-02]\n",
            " [-5.73380068e-02 -6.36745468e-02  1.57354772e-01  4.91884835e-02\n",
            "   6.02696575e-02 -4.15553786e-02  2.82220375e-02  3.40568870e-02\n",
            "  -1.09081358e-01  8.02298486e-02 -1.68886065e-01  1.31886140e-01\n",
            "  -1.46005660e-01 -1.78707600e-01 -1.61174983e-01]\n",
            " [-6.36745468e-02 -9.06984136e-02  4.91884835e-02  2.55653799e-01\n",
            "  -4.15553823e-02  5.64750731e-02  3.40568870e-02  4.91619036e-02\n",
            "   8.02298561e-02 -1.32523641e-01  1.50550902e-01 -2.10709795e-02\n",
            "  -2.26223320e-01  1.44791961e-01 -2.02946275e-01]\n",
            " [-3.16338986e-03 -1.26569741e-03  6.02696575e-02 -4.15553823e-02\n",
            "   7.67202228e-02 -6.17400296e-02  1.37172325e-03  8.52831814e-04\n",
            "  -1.30940124e-01  1.12015255e-01 -1.11698121e-01  7.49039277e-02\n",
            "  -1.40640531e-02 -1.12800047e-01 -3.61497253e-02]\n",
            " [-1.26569753e-03 -4.06327797e-03 -4.15553786e-02  5.64750731e-02\n",
            "  -6.17400296e-02  6.03119880e-02  8.52831814e-04  2.03518942e-03\n",
            "   1.12015262e-01 -1.18436605e-01  9.66233611e-02 -5.92888370e-02\n",
            "  -2.88251732e-02  9.70889032e-02 -6.21195510e-03]\n",
            " [-2.60320939e-02 -3.22904661e-02  2.82220375e-02  3.40568870e-02\n",
            "   1.37172325e-03  8.52831814e-04  1.45312557e-02  1.85348280e-02\n",
            "  -3.10793216e-03 -2.36854586e-03 -5.96476579e-03  1.46475947e-02\n",
            "  -3.79322469e-02 -9.86226648e-03 -3.75224650e-02]\n",
            " [-3.22904661e-02 -4.35579196e-02  3.40568870e-02  4.91619036e-02\n",
            "   8.52831814e-04  2.03518942e-03  1.85348280e-02  2.54026391e-02\n",
            "  -2.36854586e-03 -5.18881902e-03  4.61359043e-03  1.59167890e-02\n",
            "  -5.01244962e-02  8.00890208e-04 -4.92210686e-02]\n",
            " [ 6.89016422e-03  3.75220901e-03 -1.09081358e-01  8.02298561e-02\n",
            "  -1.30940124e-01  1.12015262e-01 -3.10793216e-03 -2.36854586e-03\n",
            "   2.34751970e-01 -2.15246424e-01  2.02335179e-01 -1.34660468e-01\n",
            "   8.24767351e-03  2.04489946e-01  4.96032387e-02]\n",
            " [ 3.75220878e-03  1.02691706e-02  8.02298486e-02 -1.32523641e-01\n",
            "   1.12015255e-01 -1.18436605e-01 -2.36854586e-03 -5.18881902e-03\n",
            "  -2.15246424e-01  2.48313129e-01 -2.01027304e-01  1.17767610e-01\n",
            "   8.83056968e-02 -2.01960310e-01  4.22868580e-02]\n",
            " [ 2.11953651e-02 -3.81092401e-03 -1.68886065e-01  1.50550902e-01\n",
            "  -1.11698121e-01  9.66233611e-02 -5.96476579e-03  4.61359043e-03\n",
            "   2.02335179e-01 -2.01027304e-01  8.76570463e-01  3.05031270e-01\n",
            "   5.20228863e-01  8.87395918e-01  5.57173669e-01]\n",
            " [-3.16399708e-02 -3.06939967e-02  1.31886140e-01 -2.10709795e-02\n",
            "   7.49039277e-02 -5.92888370e-02  1.46475947e-02  1.59167890e-02\n",
            "  -1.34660468e-01  1.17767610e-01  3.05031270e-01  6.32164478e-01\n",
            "   4.20049936e-01  2.98533440e-01  3.97942334e-01]\n",
            " [ 7.52925947e-02  9.42766815e-02 -1.46005660e-01 -2.26223320e-01\n",
            "  -1.40640531e-02 -2.88251732e-02 -3.79322469e-02 -5.01244962e-02\n",
            "   8.24767351e-03  8.83056968e-02  5.20228863e-01  4.20049936e-01\n",
            "   8.21724772e-01  5.30263007e-01  8.07408869e-01]\n",
            " [ 2.90156864e-02  3.47003620e-03 -1.78707600e-01  1.44791961e-01\n",
            "  -1.12800047e-01  9.70889032e-02 -9.86226648e-03  8.00890208e-04\n",
            "   2.04489946e-01 -2.01960310e-01  8.87395918e-01  2.98533440e-01\n",
            "   5.30263007e-01  9.00073171e-01  5.67374229e-01]\n",
            " [ 7.46478736e-02  9.24869329e-02 -1.61174983e-01 -2.02946275e-01\n",
            "  -3.61497253e-02 -6.21195510e-03 -3.75224650e-02 -4.92210686e-02\n",
            "   4.96032387e-02  4.22868580e-02  5.57173669e-01  3.97942334e-01\n",
            "   8.07408869e-01  5.67374229e-01  8.01735222e-01]]\n",
            "new smallest eigenvelue: -1.9409463e-06\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "training_skeleton.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMVchwr5OG/wA3v8jKmk6Z8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}