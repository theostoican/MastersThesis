{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theostoican/MastersThesis/blob/main/training_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4cKo7_tWleLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b79c81-b3fd-4d31-d2f9-c4995a3ad66f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dict_minimize in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from dict_minimize) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from dict_minimize) (1.4.1)\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import csv\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "!pip install dict_minimize\n",
        "from dict_minimize.torch_api import minimize\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8SjHkIMoI_B"
      },
      "source": [
        "# Various modelling parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "F8ktizbMoKWO"
      },
      "outputs": [],
      "source": [
        "#N is batch size; D_in is input dimension;\n",
        "#H is the dimension of the hidden layer; D_out is output dimension.\n",
        "N, D_in, H_teacher, H_student, D_out = 1, 2, 4, 5, 1\n",
        "num_experiments = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ptEq_k5KeK6"
      },
      "source": [
        "# Dataset creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7WSK5OS-_Jb",
        "outputId": "bd0c1809-bb0b-403f-8bcc-13ef3f22736f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1681\n"
          ]
        }
      ],
      "source": [
        "def construct_dataset():\n",
        "  data = []\n",
        "  for y in np.arange(-5, 5.1, .25):\n",
        "    for x in np.arange(-5, 5.1, .25):\n",
        "      data.append([x, y])\n",
        "  return data\n",
        "\n",
        "data = torch.Tensor(construct_dataset()) \n",
        "print(len(construct_dataset()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0ZEwEx3Kg9_"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QLlxqBcnzo2e"
      },
      "outputs": [],
      "source": [
        "class TeacherNetwork(nn.Module):\n",
        "  def __init__(self, D_in, H, D_out):\n",
        "    \"\"\"\n",
        "    In the constructor we instantiate two nn.Linear modules and assign them as\n",
        "    member variables.\n",
        "\n",
        "    D_in: input dimension\n",
        "    H: dimension of hidden layer\n",
        "    D_out: output dimension of the first layer\n",
        "    \"\"\"\n",
        "    super(TeacherNetwork, self).__init__()\n",
        "    self.linear1 = nn.Linear(D_in, H, bias=False) \n",
        "    self.linear2 = nn.Linear(H, D_out, bias=False)\n",
        "    self.linear1.weight = torch.nn.Parameter(torch.transpose(torch.Tensor([[0.6, -0.5, -0.2, 0.1], [0.5, 0.5, -0.6, -0.6]]), 0, 1))\n",
        "    self.linear2.weight = torch.nn.Parameter(torch.transpose(torch.Tensor([[1], [-1], [1], [-1]]), 0, 1))\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    In the forward function we accept a Variable of input data and we must\n",
        "    return a Variable of output data. We can use Modules defined in the\n",
        "    constructor as well as arbitrary operators on Variables.\n",
        "    \"\"\"\n",
        "    h_sigmoid = torch.sigmoid(self.linear1(x))\n",
        "    y_pred = self.linear2(h_sigmoid)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "COkLdjEOmBJV"
      },
      "outputs": [],
      "source": [
        "class StudentNetwork(nn.Module):\n",
        "  def __init__(self, D_in, H, D_out):\n",
        "    \"\"\"\n",
        "    In the constructor we instantiate two nn.Linear modules and assign them as\n",
        "    member variables.\n",
        "\n",
        "    D_in: input dimension\n",
        "    H: dimension of hidden layer\n",
        "    D_out: output dimension of the first layer\n",
        "    \"\"\"\n",
        "    super(StudentNetwork, self).__init__()\n",
        "    self.linear1 = nn.Linear(D_in, H, bias=False) \n",
        "    self.linear2 = nn.Linear(H, D_out, bias=False)\n",
        "    nn.init.xavier_uniform_(self.linear1.weight)\n",
        "    nn.init.xavier_uniform_(self.linear2.weight)\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    In the forward function we accept a Variable of input data and we must\n",
        "    return a Variable of output data. We can use Modules defined in the\n",
        "    constructor as well as arbitrary operators on Variables.\n",
        "    \"\"\"\n",
        "    h_sigmoid = torch.sigmoid(self.linear1(x))\n",
        "    y_pred = self.linear2(h_sigmoid)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh4A8WS3HzeU"
      },
      "source": [
        "# Generation of the labels based on the teacher model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ILSXsIRu3U18"
      },
      "outputs": [],
      "source": [
        "teacher_model = TeacherNetwork(D_in, H_teacher, D_out)\n",
        "y_labels = teacher_model(data).detach()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZrYxLLwKk6Q"
      },
      "source": [
        "# Training helper method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kS2Ri_ya9Npv"
      },
      "outputs": [],
      "source": [
        "def train(model, x, y_labels, N = 1000, Ninner = 10**3, Nstart = 10,\n",
        "          maxtime = 10 ** 3, nlopt_threshold = 1e-7,\n",
        "          collect_history = True):\n",
        "  optimizer = torch.optim.Adam(model.parameters()) #, lr=0.0001)\n",
        "  loss_fn = nn.MSELoss()\n",
        "  loss_vals = []\n",
        "  trace = []\n",
        "  if collect_history:\n",
        "    trace.append((copy.deepcopy(model.linear1.weight.data.detach().numpy()),\n",
        "                  copy.deepcopy(model.linear2.weight.data.detach().numpy())))\n",
        "  for i in range(N):\n",
        "    loss_tmp = []\n",
        "    for j in range(Ninner):\n",
        "      y = model(x)\n",
        "      loss = loss_fn(y, y_labels)\n",
        "      loss_grad = torch.autograd.grad(loss, model.parameters(), retain_graph=True)\n",
        "      loss_tmp.append(loss.item())\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward(retain_graph=True)\n",
        "      optimizer.step()\n",
        "      if i == 0 and (j % Nstart == 0) and j > 0:\n",
        "        loss_vals.append(np.mean(loss_tmp[j - Nstart : j]))\n",
        "        if collect_history:\n",
        "          trace.append((copy.deepcopy(model.linear1.weight.data.detach().numpy()),\n",
        "                        copy.deepcopy(model.linear2.weight.data.detach().numpy())))\n",
        "    loss_vals.append(np.mean(loss_tmp))\n",
        "    if collect_history:\n",
        "      trace.append((copy.deepcopy(model.linear1.weight.data.detach().numpy()),\n",
        "                    copy.deepcopy(model.linear2.weight.data.detach().numpy())))\n",
        "    # stopping criterion\n",
        "    cnt = 0\n",
        "    for g in loss_grad:\n",
        "        g_vector = g.contiguous().view(-1) if cnt == 0 else torch.cat([g_vector, g.contiguous().view(-1)])\n",
        "        cnt = 1\n",
        "    print(\"Iteration: %d, loss: %s, gradient norm: %s\" % (Ninner * i, np.mean(loss_tmp), torch.norm(g_vector)))\n",
        "    if torch.norm(g_vector) <= 2e-6:\n",
        "      break\n",
        "  return loss_vals, trace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlZpml_4MOQD"
      },
      "source": [
        "# Hessian evaluation helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mXEHxyklMQgi"
      },
      "outputs": [],
      "source": [
        "def eval_hessian(loss_grad, model):\n",
        "    cnt = 0\n",
        "    for g in loss_grad:\n",
        "        g_vector = g.contiguous().view(-1) if cnt == 0 else torch.cat([g_vector, g.contiguous().view(-1)])\n",
        "        cnt = 1\n",
        "    grad_norm = torch.norm(g_vector)\n",
        "    l = g_vector.size(0)\n",
        "    hessian = torch.zeros(l, l)\n",
        "    for idx in range(l):\n",
        "        grad2rd = torch.autograd.grad(g_vector[idx], model.parameters(), create_graph=True)\n",
        "        cnt = 0\n",
        "        for g in grad2rd: \n",
        "            g2 = g.contiguous().view(-1) if cnt == 0 else torch.cat([g2, g.contiguous().view(-1)])\n",
        "            cnt = 1\n",
        "        hessian[idx] = g2\n",
        "    hessian[:, idx] = g2\n",
        "    return grad_norm.cpu().data.numpy(), hessian.cpu().data.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV8HjfUxcupO"
      },
      "source": [
        "# Actual training and hessian computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-4dScUFCP-2",
        "outputId": "4d797395-a430-435b-dfc7-f47d400cfe23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0, loss: 0.03345492475561332, gradient norm: tensor(0.0066)\n",
            "Iteration: 1000, loss: 0.0008598318077856675, gradient norm: tensor(0.0028)\n",
            "Iteration: 2000, loss: 0.00035909458450623786, gradient norm: tensor(0.0011)\n",
            "Iteration: 3000, loss: 0.0002629026825306937, gradient norm: tensor(0.0007)\n",
            "Iteration: 4000, loss: 0.00023224779403244612, gradient norm: tensor(0.0005)\n",
            "Iteration: 5000, loss: 0.0002025335907092085, gradient norm: tensor(0.0004)\n",
            "Iteration: 6000, loss: 0.0001730091286735842, gradient norm: tensor(0.0003)\n",
            "Iteration: 7000, loss: 0.00014120709798589814, gradient norm: tensor(0.0002)\n",
            "Iteration: 8000, loss: 0.00011983784068434034, gradient norm: tensor(3.7106e-05)\n",
            "Iteration: 9000, loss: 0.00011608801779948407, gradient norm: tensor(3.0726e-05)\n",
            "Iteration: 10000, loss: 0.00011109463268803665, gradient norm: tensor(4.6454e-05)\n",
            "Iteration: 11000, loss: 0.00010254112136317417, gradient norm: tensor(4.7536e-05)\n",
            "Iteration: 12000, loss: 8.330993527670217e-05, gradient norm: tensor(0.0001)\n",
            "Iteration: 13000, loss: 1.5120902598027897e-05, gradient norm: tensor(3.5461e-05)\n",
            "Iteration: 14000, loss: 3.167458837197046e-06, gradient norm: tensor(0.0001)\n",
            "Iteration: 15000, loss: 1.1337428082924816e-06, gradient norm: tensor(7.2077e-06)\n",
            "Iteration: 16000, loss: 9.309973019639984e-07, gradient norm: tensor(0.0003)\n",
            "Iteration: 17000, loss: 8.215033338387911e-07, gradient norm: tensor(6.1871e-05)\n",
            "Iteration: 18000, loss: 7.38862642492677e-07, gradient norm: tensor(6.2658e-05)\n",
            "Iteration: 19000, loss: 6.713666043083322e-07, gradient norm: tensor(7.9855e-05)\n",
            "Iteration: 20000, loss: 6.142154912822662e-07, gradient norm: tensor(9.5245e-05)\n",
            "Iteration: 21000, loss: 5.653331256780803e-07, gradient norm: tensor(0.0001)\n",
            "Iteration: 22000, loss: 5.216468169351174e-07, gradient norm: tensor(5.9167e-06)\n",
            "Iteration: 23000, loss: 4.843629395168137e-07, gradient norm: tensor(0.0003)\n",
            "Iteration: 24000, loss: 4.5006040107864465e-07, gradient norm: tensor(0.0002)\n",
            "Iteration: 25000, loss: 4.1991783601247336e-07, gradient norm: tensor(0.0008)\n",
            "Iteration: 26000, loss: 3.908759466924039e-07, gradient norm: tensor(0.0007)\n",
            "Iteration: 27000, loss: 3.689182529740265e-07, gradient norm: tensor(0.0001)\n",
            "Iteration: 28000, loss: 3.442244032783037e-07, gradient norm: tensor(3.5117e-05)\n",
            "Iteration: 29000, loss: 3.2394729839779757e-07, gradient norm: tensor(6.4087e-05)\n",
            "Iteration: 30000, loss: 3.066014042474308e-07, gradient norm: tensor(0.0002)\n",
            "Iteration: 31000, loss: 2.862120199438323e-07, gradient norm: tensor(2.3305e-05)\n",
            "Iteration: 32000, loss: 2.7205053510215295e-07, gradient norm: tensor(0.0004)\n",
            "Iteration: 33000, loss: 2.5655461917040157e-07, gradient norm: tensor(0.0002)\n",
            "Iteration: 34000, loss: 2.423886998741409e-07, gradient norm: tensor(0.0001)\n",
            "Iteration: 35000, loss: 2.310565471219661e-07, gradient norm: tensor(2.9750e-05)\n",
            "Iteration: 36000, loss: 2.1999548690132542e-07, gradient norm: tensor(7.1424e-05)\n",
            "Iteration: 37000, loss: 2.0756458604864746e-07, gradient norm: tensor(0.0002)\n",
            "Iteration: 38000, loss: 1.9808390858599979e-07, gradient norm: tensor(0.0002)\n",
            "Iteration: 39000, loss: 1.8964448584313232e-07, gradient norm: tensor(0.0002)\n",
            "Iteration: 40000, loss: 1.8028471122022437e-07, gradient norm: tensor(0.0001)\n",
            "Iteration: 41000, loss: 1.7137737695804845e-07, gradient norm: tensor(1.3859e-06)\n",
            "smallest eigenvalue:  2.3438884e-06\n"
          ]
        }
      ],
      "source": [
        "student_model = StudentNetwork(D_in, H_student, D_out)\n",
        "loss_vals, trace = train(student_model, data, y_labels)\n",
        "last_loss_val = loss_vals[-1]\n",
        "\n",
        "loss_grad = torch.autograd.grad(nn.MSELoss()(student_model(data), y_labels), student_model.parameters(), create_graph=True)\n",
        "grad_norm, hessian = eval_hessian(loss_grad, student_model)\n",
        "smallest_eigenvalue = np.min(np.linalg.eigvals(hessian))\n",
        "\n",
        "print('smallest eigenvalue: ', smallest_eigenvalue)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F7kBJPoLS_h"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JYMYC8b5VqT1"
      },
      "outputs": [],
      "source": [
        "teacher_neurons_x = [0.6, -0.5, -0.2, 0.1]\n",
        "teacher_neurons_y = [0.5, 0.5, -0.6, -0.6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mflgj_AbLToB",
        "outputId": "9a72ffe9-aeb0-4e19-e1bb-603ab5ec872b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7fd1387f0910>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "neuron_0_w_x = []\n",
        "neuron_0_w_y = []\n",
        "neuron_0_a = []\n",
        "\n",
        "neuron_1_w_x = []\n",
        "neuron_1_w_y = []\n",
        "neuron_1_a = []\n",
        "\n",
        "neuron_2_w_x = []\n",
        "neuron_2_w_y = []\n",
        "neuron_2_a = []\n",
        "\n",
        "neuron_3_w_x = []\n",
        "neuron_3_w_y = []\n",
        "neuron_3_a = []\n",
        "\n",
        "neuron_4_w_x = []\n",
        "neuron_4_w_y = []\n",
        "neuron_4_a = []\n",
        "\n",
        "for (inp_weights, out_weights) in trace:\n",
        "  neuron_0_w_x.append(inp_weights[0][0])\n",
        "  neuron_0_w_y.append(inp_weights[0][1])\n",
        "  neuron_0_a.append(out_weights[0][0])\n",
        "\n",
        "  neuron_1_w_x.append(inp_weights[1][0])\n",
        "  neuron_1_w_y.append(inp_weights[1][1])\n",
        "  neuron_1_a.append(out_weights[0][1])\n",
        "\n",
        "  neuron_2_w_x.append(inp_weights[2][0])\n",
        "  neuron_2_w_y.append(inp_weights[2][1])\n",
        "  neuron_2_a.append(out_weights[0][2])\n",
        "\n",
        "  neuron_3_w_x.append(inp_weights[3][0])\n",
        "  neuron_3_w_y.append(inp_weights[3][1])\n",
        "  neuron_3_a.append(out_weights[0][3])\n",
        "\n",
        "  neuron_4_w_x.append(inp_weights[4][0])\n",
        "  neuron_4_w_y.append(inp_weights[4][1])\n",
        "  neuron_4_a.append(out_weights[0][4])\n",
        "\n",
        "plt.plot(neuron_0_w_x, neuron_0_w_y)\n",
        "plt.plot(neuron_1_w_x, neuron_1_w_y)\n",
        "plt.plot(neuron_2_w_x, neuron_2_w_y)\n",
        "plt.plot(neuron_3_w_x, neuron_3_w_y)\n",
        "plt.plot(neuron_4_w_x, neuron_4_w_y)\n",
        "\n",
        "plt.scatter(teacher_neurons_x, teacher_neurons_y, marker=\"*\")\n",
        "\n",
        "outgoing_weights = [neuron_0_a[-1], neuron_1_a[-1], neuron_2_a[-1], neuron_3_a[-1], neuron_4_a[-1]]\n",
        "plt.scatter([neuron_0_w_x[-1], neuron_1_w_x[-1], neuron_2_w_x[-1], neuron_3_w_x[-1], neuron_4_w_x[-1]],\n",
        "            [neuron_0_w_y[-1], neuron_1_w_y[-1], neuron_2_w_y[-1], neuron_3_w_y[-1], neuron_4_w_y[-1]],\n",
        "            c = outgoing_weights,\n",
        "            cmap=matplotlib.cm.jet)\n",
        "plt.colorbar()\n",
        "\n",
        "# Teacher's neurons\n",
        "#[0.6, -0.5, -0.2, 0.1],\n",
        "#[0.5, 0.5, -0.6, -0.6],"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second order optimization"
      ],
      "metadata": {
        "id": "JjTe7aE14Dac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DummyNetwork(nn.Module):\n",
        "  def __init__(self, D_in, H, D_out, w_in, w_out):\n",
        "    \"\"\"\n",
        "    In the constructor we instantiate two nn.Linear modules and assign them as\n",
        "    member variables.\n",
        "\n",
        "    D_in: input dimension\n",
        "    H: dimension of hidden layer\n",
        "    D_out: output dimension of the first layer\n",
        "    \"\"\"\n",
        "    super(DummyNetwork, self).__init__()\n",
        "    self.linear1 = nn.Linear(D_in, H, bias=False) \n",
        "    self.linear2 = nn.Linear(H, D_out, bias=False)\n",
        "    self.linear1.weight = torch.nn.Parameter(w_in)\n",
        "    self.linear2.weight = torch.nn.Parameter(w_out)\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    In the forward function we accept a Variable of input data and we must\n",
        "    return a Variable of output data. We can use Modules defined in the\n",
        "    constructor as well as arbitrary operators on Variables.\n",
        "    \"\"\"\n",
        "    h_sigmoid = torch.sigmoid(self.linear1(x))\n",
        "    y_pred = self.linear2(h_sigmoid)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "WDicCa3cV1xM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def d_loss(params):\n",
        "  w_in, w_out = params[\"w_in\"], params[\"w_out\"]\n",
        "  dummy_model = DummyNetwork(D_in, H_student, D_out, w_in, w_out)\n",
        "  obj = nn.MSELoss()(dummy_model(data), y_labels)\n",
        "  dw_in, dw_out = torch.autograd.grad(obj, dummy_model.parameters())\n",
        "  d_obj = OrderedDict([(\"w_in\", dw_in), (\"w_out\", dw_out)])\n",
        "  return obj, d_obj"
      ],
      "metadata": {
        "id": "TuACp-6HWtBD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = OrderedDict([(\"w_in\", torch.Tensor(trace[-1][0])), (\"w_out\", torch.Tensor(trace[-1][1]))])\n",
        "lb_dict = OrderedDict([(\"w_in\", torch.Tensor(trace[-1][0] - 1)), (\"w_out\", torch.Tensor(trace[-1][1] - 1))])\n",
        "ub_dict = OrderedDict([(\"w_in\", torch.Tensor(trace[-1][0] + 1)), (\"w_out\", torch.Tensor(trace[-1][1] + 1))])\n",
        "print('old params: ',params)\n",
        "# params = minimize(d_loss, params, method=\"\", lb_dict = lb_dict, ub_dict = ub_dict,\n",
        "#                   options={\"disp\": True , \"maxiter\": 10 ** 3}, tol=1e-8)\n",
        "params = minimize(d_loss, params, method=\"SLSQP\", lb_dict = lb_dict, ub_dict = ub_dict,\n",
        "                  options={\"disp\": True , \"maxiter\": 10 ** 4}, tol=1e-40)\n",
        "print('new params: ',params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm6OGZBNYuV7",
        "outputId": "f8124ebc-7e5b-4771-c956-4ec688dab56d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "old params:  OrderedDict([('w_in', tensor([[-2.4470e-01, -6.2086e-01],\n",
            "        [-6.1159e-01, -5.0734e-01],\n",
            "        [ 5.1418e-01, -5.0806e-01],\n",
            "        [-2.8453e-03, -1.9095e-04],\n",
            "        [-1.3787e-01,  6.2348e-01]])), ('w_out', tensor([[ 0.7732, -0.9763,  0.9600, -1.5138,  0.7570]]))])\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: 1.5222880733745114e-07\n",
            "            Iterations: 1\n",
            "            Function evaluations: 1\n",
            "            Gradient evaluations: 1\n",
            "new params:  OrderedDict([('w_in', tensor([[-2.4470e-01, -6.2086e-01],\n",
            "        [-6.1159e-01, -5.0734e-01],\n",
            "        [ 5.1418e-01, -5.0806e-01],\n",
            "        [-2.8453e-03, -1.9095e-04],\n",
            "        [-1.3787e-01,  6.2348e-01]], requires_grad=True)), ('w_out', tensor([[ 0.7732, -0.9763,  0.9600, -1.5138,  0.7570]], requires_grad=True))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New smallest eigenvalue"
      ],
      "metadata": {
        "id": "9flDuKrBgJ68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_model = DummyNetwork(D_in, H_student, D_out, params[\"w_in\"], params[\"w_out\"])\n",
        "print(nn.MSELoss()(dummy_model(data), y_labels))\n",
        "loss_grad = torch.autograd.grad(nn.MSELoss()(dummy_model(data), y_labels), dummy_model.parameters(), create_graph=True)\n",
        "grad_norm, hessian = eval_hessian(loss_grad, dummy_model)\n",
        "print(hessian)\n",
        "smallest_eigenvalue = np.min(np.linalg.eigvals(hessian))\n",
        "print('new smallest eigenvelue:', smallest_eigenvalue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwNZPkIvek9Y",
        "outputId": "42442871-ae2e-4550-9a03-55ef819e0d2a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5223e-07, grad_fn=<MseLossBackward0>)\n",
            "[[ 2.66191810e-01 -9.68889147e-02 -2.42168635e-01  1.44997969e-01\n",
            "   1.59882918e-01  2.42555756e-02 -7.12640941e-01  2.01739103e-01\n",
            "   2.12254941e-01 -1.69030502e-02 -1.97368022e-02 -1.51785880e-01\n",
            "   1.90139294e-01 -1.31407147e-03 -1.04171313e-01]\n",
            " [-9.68889147e-02  1.24728888e-01  1.44997969e-01 -1.96210340e-01\n",
            "   2.42555719e-02  1.08888745e-01  2.01739103e-01 -4.65421617e-01\n",
            "  -1.69030484e-02  8.57481584e-02 -1.19125381e-01 -4.17125449e-02\n",
            "  -1.31749272e-01  3.20505205e-04  1.47695005e-01]\n",
            " [-2.42168635e-01  1.44997969e-01  3.05977076e-01 -2.61726409e-01\n",
            "  -1.16374664e-01  7.95138720e-03  6.78760588e-01 -4.20444369e-01\n",
            "  -1.52438313e-01  4.53380160e-02 -5.46782464e-02  9.73710790e-02\n",
            "  -2.11166993e-01  1.22272724e-03  1.54134229e-01]\n",
            " [ 1.44997969e-01 -1.96210355e-01 -2.61726409e-01  3.71663243e-01\n",
            "   7.95138814e-03 -1.33401722e-01 -4.20444369e-01  7.70907760e-01\n",
            "   4.53380160e-02 -1.13516875e-01  1.89496532e-01  6.03227280e-02\n",
            "   2.30605781e-01 -6.93103299e-04 -2.35882223e-01]\n",
            " [ 1.59882918e-01  2.42555719e-02 -1.16374664e-01  7.95138720e-03\n",
            "   3.59857410e-01  2.70624071e-01 -7.70384252e-01 -4.18897182e-01\n",
            "   2.51339644e-01  1.17016695e-01 -1.84306964e-01 -2.42947340e-01\n",
            "   8.82261917e-02 -1.50081166e-03  8.12662989e-02]\n",
            " [ 2.42555719e-02  1.08888760e-01  7.95138720e-03 -1.33401722e-01\n",
            "   2.70624101e-01  3.63921165e-01 -4.18897182e-01 -7.76036501e-01\n",
            "   1.17016695e-01  1.68284506e-01 -2.43162945e-01 -2.29988813e-01\n",
            "  -8.57657120e-02 -8.85100395e-04  2.10266799e-01]\n",
            " [-7.12640941e-01  2.01739103e-01  6.78760588e-01 -4.20444369e-01\n",
            "  -7.70384192e-01 -4.18897182e-01  2.50638342e+00 -1.15223229e-05\n",
            "  -7.14535952e-01 -1.15721457e-01  2.31482580e-01  5.86155891e-01\n",
            "  -5.12855887e-01  4.71047265e-03  1.31145731e-01]\n",
            " [ 2.01739088e-01 -4.65421617e-01 -4.20444369e-01  7.70907760e-01\n",
            "  -4.18897182e-01 -7.76036441e-01 -1.15334988e-05  2.50645590e+00\n",
            "  -1.15721449e-01 -4.29845482e-01  6.86811626e-01  4.62249249e-01\n",
            "   5.05260348e-01  3.16961494e-04 -7.10569203e-01]\n",
            " [ 2.12254941e-01 -1.69030502e-02 -1.52438328e-01  4.53380160e-02\n",
            "   2.51339644e-01  1.17016695e-01 -7.14535952e-01 -1.15721457e-01\n",
            "   2.57889450e-01  5.35233915e-02 -1.11433238e-01 -1.95897669e-01\n",
            "   1.42227739e-01 -1.35761686e-03 -1.02109909e-02]\n",
            " [-1.69030502e-02  8.57481509e-02  4.53380160e-02 -1.13516882e-01\n",
            "   1.17016695e-01  1.68284506e-01 -1.15721449e-01 -4.29845452e-01\n",
            "   5.35233915e-02  9.91297662e-02 -1.33205071e-01 -1.05084382e-01\n",
            "  -6.62199184e-02 -2.71735218e-04  1.25107750e-01]\n",
            " [-1.97368003e-02 -1.19125448e-01 -5.46783060e-02  1.89496607e-01\n",
            "  -1.84306845e-01 -2.43162975e-01  2.31482580e-01  6.86810374e-01\n",
            "  -1.11433096e-01 -1.33204758e-01  7.16778874e-01  6.87520385e-01\n",
            "   5.88661015e-01  5.00521660e-01  3.16779733e-01]\n",
            " [-1.51785821e-01 -4.17124927e-02  9.73710790e-02  6.03229068e-02\n",
            "  -2.42947370e-01 -2.29988918e-01  5.86155653e-01  4.62249875e-01\n",
            "  -1.95897609e-01 -1.05084531e-01  6.87520385e-01  7.37116516e-01\n",
            "   4.74645674e-01  5.01160324e-01  4.01161224e-01]\n",
            " [ 1.90139100e-01 -1.31749243e-01 -2.11167172e-01  2.30605736e-01\n",
            "   8.82263109e-02 -8.57655108e-02 -5.12855887e-01  5.05259395e-01\n",
            "   1.42227799e-01 -6.62199706e-02  5.88661015e-01  4.74645674e-01\n",
            "   7.18450725e-01  4.99099940e-01  3.25849950e-01]\n",
            " [-1.31403119e-03  3.20478808e-04  1.22274365e-03 -6.93030655e-04\n",
            "  -1.50085613e-03 -8.85264948e-04  4.71047126e-03  3.16485763e-04\n",
            "  -1.35763967e-03 -2.71739438e-04  5.00521660e-01  5.01160264e-01\n",
            "   4.99099910e-01  5.00008941e-01  5.00156820e-01]\n",
            " [-1.04171313e-01  1.47695005e-01  1.54134229e-01 -2.35882223e-01\n",
            "   8.12662989e-02  2.10266799e-01  1.31145731e-01 -7.10569203e-01\n",
            "  -1.02109909e-02  1.25107750e-01  3.16779733e-01  4.01161224e-01\n",
            "   3.25849950e-01  5.00156820e-01  7.13481247e-01]]\n",
            "new smallest eigenvelue: 2.3438884e-06\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "training_skeleton.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOoX5wzJJqfav5tJyLCmOI2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}